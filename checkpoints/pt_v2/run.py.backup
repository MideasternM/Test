from __future__ import print_function
import os
import argparse
import torch
import torch.nn as nn
import torch.optim as optim
from utils import config, metric
from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR
from dataset.loader import TorchDataset, TorchDataLoader
from models.DGCNN.dgcnn_model import DGCNN
from models.PointNet2.pointnet2_model import PointNet2
from models.PointCNN.pointcnn_model import PointCNN
from models.PointTransformer.ptv2 import PTSegV2
from models.PT_V3.ptv3 import PointTransformerV3
from dataset.reader import read_h_matrix_file_list
from eval import test
import numpy as np
from utils.io import IOStream, load_model, save_model
from utils.loss import ConsistencyLoss, HeirarchicalCrossEntropyLoss, SupConLoss
from torch.cuda.amp import autocast, GradScaler
from DataPreProcessing import DataProcess
from DataAug import AugmentedData
from pseudo_label import gen_label
from collections import OrderedDict
import matplotlib.pyplot as plt
import matplotlib


def _init_():
    if not os.path.exists('checkpoints'):
        os.makedirs('checkpoints')
    if not os.path.exists('checkpoints/'+args.exp_name):
        os.makedirs('checkpoints/'+args.exp_name)
    if not os.path.exists('checkpoints/'+args.exp_name+'/'+'models'):
        os.makedirs('checkpoints/'+args.exp_name+'/'+'models')
    os.system('cp run.py checkpoints'+'/'+args.exp_name+'/'+'run.py.backup')
    os.system('cp configs/train_setting.yaml checkpoints/' + args.exp_name + '/train_setting.backup')


def full_batch_size(batch_size, *np_args):
    sample_size = np_args[0].shape[0]
    init_ind = np.arange(sample_size)
    if sample_size < batch_size:
        res_ind = np.random.randint(0, sample_size, (batch_size - sample_size, ))
        np_args = [np.concatenate([arr, arr[res_ind]]) for arr in np_args]
    return tuple([init_ind] + list(np_args))


def cal_correct(pred, target):
    return torch.eq(target.squeeze(), pred.argmax(dim=2)).sum().item()


def min_max_normalize(data, range_min=0, range_max=1):
    data_min = data.min(dim=2, keepdim=True)[0]  # (batch_size, num_features, 1)
    data_max = data.max(dim=2, keepdim=True)[0]  # (batch_size, num_features, 1)
    
    normalized_data = range_min + (data - data_min) / (data_max - data_min + 1e-8) * (range_max - range_min)
    return normalized_data


def train(args, io, cfg, HM):
    CM = [HM[i + 1, i] for i in range(len(HM.classes_num) - 1)]
    CLW = cfg.TRAIN.CONSISTENCY_WEIGHTS
    num_class = cfg.DATASET.DATA.LABEL_NUMBER
    l = args.mc_level
    enable_consistency_loss = cfg.TRAIN.CONSISTENCY_LOSS
    device = torch.device("cuda" if args.cuda else "cpu")
    if enable_consistency_loss and l == -1:
        ConsistencyLossCal = ConsistencyLoss(CM, CLW, device)
    max_epoch = cfg.TRAIN.MAX_EPOCH
    
    #Try to load models
    if args.model == 'dgcnn':
        model = DGCNN(cfg).to(device)
        model_tea = DGCNN(cfg).to(device)
    elif args.model == 'pointnet2':
        model = PointNet2(cfg, args).to(device)
        # model_tea=PointNet2(cfg, args).to(device)
    elif args.model == 'pointcnn':
        model = PointCNN(cfg).to(device)
        model_tea = PointCNN(cfg).to(device)
    elif args.model == 'point_transformer':
        model = PTSegV2().to(device)
    elif args.model == 'pt_v3':
        model = PointTransformerV3().to(device)
    else:
        raise Exception("Not implemented")
    if cfg.TRAIN.IS_PRETRAINED:
        model = load_model(args, cfg, model)
        # model_tea = load_model(args, cfg, model_tea)
    elif len(cfg.DEVICES.GPU_ID) > 1:
        model = nn.DataParallel(model, device_ids = cfg.DEVICES.GPU_ID)
        # model_tea = nn.DataParallel(model, device_ids = cfg.DEVICES.GPU_ID)
    train_dataset = TorchDataset("TRAIN_SET", params=cfg.DATASET, is_training=True, )
    train_loader = TorchDataLoader(dataset=train_dataset, batch_size=cfg.TRAIN.BATCH_SIZE,
                                   num_workers=int(cfg.TRAIN.BATCH_SIZE/4))
                                   
    validation_dataset = TorchDataset("VALIDATION_SET", params=cfg.DATASET,
                                      is_training=True, )
    validation_loader = TorchDataLoader(dataset=validation_dataset,
                                        batch_size=cfg.TRAIN.BATCH_SIZE,
                                        num_workers=int(cfg.TRAIN.BATCH_SIZE/4))
    io.cprint('length of train loader: %d' % (len(train_loader)))

    HCrossEntropy = HeirarchicalCrossEntropyLoss(train_dataset.data_sampler.label_weights,device)
    l1_loss = nn.SmoothL1Loss(reduction='mean')
    sup_con_loss = SupConLoss()
    # cross_entropy_loss = nn.CrossEntropyLoss(label_smoothing = 0.2)
    
    # if args.model == 'point_transformer' or args.model == 'pt_v3':
    #     opt = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)
    # else:
    opt = optim.SGD(model.parameters(), lr=cfg.TRAIN.LEARNING_RATE, momentum=cfg.TRAIN.MOMENTUM, weight_decay=1e-4)

    if cfg.TRAIN.SCHEDULER == 'cos':
        if args.model == 'point_transformer' or args.model == 'pt_v3':
            scheduler = CosineAnnealingLR(opt, max_epoch, eta_min=1e-5)
        else:
            scheduler = CosineAnnealingLR(opt, max_epoch, eta_min=1e-3)
    elif cfg.TRAIN.SCHEDULER == 'step':
        scheduler = StepLR(opt, 20, 0.5)

    for epoch in range(max_epoch):
        ####################
        # Train
        ####################
        io.cprint('___________________epoch %d_____________________' %(epoch))
        train_loss = 0.0
        total_num = 0
        count = 0
        cfs_mtx_list = [metric.IouMetric(list(range(l))) for l in cfg.DATASET.DATA.LABEL_NUMBER]
        model.train()
        for batch_idx, data_ in enumerate(train_loader):
            points_centered, labels, colors, label_weights = data_
            if labels.shape[0] < cfg.TRAIN.BATCH_SIZE:
                break

            # labels = DataProcess(labels,0)
            # aug_data=AugmentedData(points_centered,colors,labels)
            # aug_point,aug_color,aug_label=aug_data.augment(points_centered,colors,labels)
            
            points_clrs = torch.FloatTensor(np.concatenate([points_centered, colors], axis=-1))
            # points_clrs_aug = torch.FloatTensor(np.concatenate([aug_point, aug_color], axis=-1))
            points_clrs = points_clrs.to(device).permute(0, 2, 1) # (batch_size, dim, nums_point)
            # points_clrs_aug = points_clrs_aug.to(device).permute(0, 2, 1)
            labels = torch.LongTensor(labels).to(device)
            label_weights = torch.Tensor(label_weights).to(device)
            num_points = labels.size()[1]
            batch_size = labels.size()[0]
            opt.zero_grad()
            labels_np = labels.cpu().detach().numpy()
            labels = torch.chunk(labels, 5, dim=2)
            label_weights = torch.chunk(label_weights, 5, dim=2)
            level_weights = cfg.TRAIN.LOSS_WEIGHTS

            if args.model == 'point_transformer':
                feat = points_clrs
                coord = points_clrs[:,:3,:]
                offset = torch.arange(0,cfg.TRAIN.BATCH_SIZE+1)*2048
                offset = offset.to('cuda')
                offset = offset.to(torch.int32)

                feat = min_max_normalize(feat, range_min=-1, range_max=1)
                coord = min_max_normalize(coord, range_min=-1, range_max=1)
                feat = feat.to(device)
                coord = coord.to(device)

            if args.model == 'pt_v3':
                feat = points_clrs
                coord = points_clrs[:,:3,:]
                offset = torch.arange(1,cfg.TRAIN.BATCH_SIZE+1)*2048
                offset = offset.to('cuda')
                offset = offset.to(torch.int32)

                feat = min_max_normalize(feat, range_min=-1, range_max=1)
                coord = min_max_normalize(coord, range_min=-1, range_max=1)
                feat = feat.to(device)
                coord = coord.to(device)

                if len(feat.size())>2: # means x0:(b, c ,n), need to be catted to (b*n, c)
                    feat = feat.transpose(1,2).contiguous() # po(b, n, 3), x0(b, n, c=3)
                    coord = coord.transpose(1,2).contiguous()
                    coord = torch.cat([coord_split.squeeze() for coord_split in coord.split(1,0)])
                    feat = torch.cat([feat_split.squeeze() for feat_split in feat.split(1,0)]) 

                input = {
                    "feat" : feat,
                    "offset" : offset,
                    "coord" : coord,
                    "grid_size" : 0.01
                }

            # seg_pred, feat, prototype, prior_feat, prior_prototype= model(points_clrs, labels)
            if args.model == 'point_transformer':
                # scaler = GradScaler()
                # with autocast():
                seg_pred = model(coord, feat, offset)
            elif args.model == 'pt_v3':
                seg_pred = model(input)
            else:
                seg_pred = model(points_clrs, labels)
            # seg_pred_tea, feat_tea, prototype_tea = model_tea(points_clrs, labels)
            con_loss = []
            prior_fea_target = []
            loss_prior = []
            loss_main = []
            # for i in range(3):
            #     loss_i = sup_con_loss(prior_feat[i][:,:-1],prior_feat[i][:,-1])
            #     con_loss.append(loss_i)
            #     indices = prior_feat[i][:, -1].long()
            #     prototype[i] = prototype[i].to(prior_feat[i].device)
            #     prior_fea_target.append(prototype[i][indices, :])
            #     loss_prior.append(l1_loss(prior_feat[i][:,:-1], prior_fea_target[i]))
            #     prior_prototype[i] = prior_prototype[i].to(prior_feat[i].device)
            #     target_main_feas = prior_prototype[i][labels[i+2], :]
            #     target_main_feas = target_main_feas.squeeze(dim=2)
            #     loss_main.append(l1_loss(feat, target_main_feas))

            MTLoss = 0.
            MTLoss_tea = 0.
            p_loss = 0

            if l == -1:
                for i in range(len(seg_pred)):
                    seg_pred_i = seg_pred[i].permute(0, 2, 1).contiguous()#(batch_size, num_points, cls)
                    # seg_pred_i_tea = seg_pred_tea[i].permute(0, 2, 1).contiguous()
                    # seg_pred_i_1 = seg_pred_i.clone()
                    # p_label = gen_label(seg_pred_i_tea,labels[i],threshold=0.7)
                    MTLoss += HCrossEntropy(seg_pred_i, labels[i], level=i) * level_weights[i]
                    # p_loss = HCrossEntropy(seg_pred_i_1, p_label, level=i) * level_weights[i]
                    # MTLoss += p_loss
                    # if i > 2:
                    #     MTLoss += loss_main[i-2] + loss_prior[i-2] + con_loss[i-2]
            else:
                seg_pred = seg_pred.permute(0, 2, 1).contiguous()
                # seg_pred_tea = seg_pred_tea.permute(0, 2, 1).contiguous()
                # seg_pred_1 = seg_pred.clone()
                # p_label = gen_label(seg_pred_tea,labels[l],threshold=0.7)
                MTLoss += HCrossEntropy(seg_pred, labels[l], level=l)
                # p_loss = HCrossEntropy(seg_pred_1, p_label, level=l)
                # MTLoss += p_loss
                pred_np = np.argmax(seg_pred.cpu().detach().numpy(), 2)      
            if enable_consistency_loss and l == -1:
                CLoss = ConsistencyLossCal(seg_pred)
                MTLoss += CLoss
            
            # if args.model == 'point_transformer':
            #     scaler.scale(MTLoss).backward()
            #     scaler.step(opt)
            #     scaler.update()
            # else:
            MTLoss.backward()
            opt.step()
            count += batch_size
            train_loss += MTLoss.item()

            # ema_keep_rate=0.95
            # student_model_dict = model.state_dict()
            # new_teacher_dict = OrderedDict()
            # for key, value in model_tea.state_dict().items():
            #     if key in student_model_dict.keys():
            #         new_teacher_dict[key] = (
            #             student_model_dict[key] *
            #             (1 - ema_keep_rate) +
            #             value * ema_keep_rate
            #         )
            #     else:
            #         raise Exception(
            #             "{} is not found in student model".format(key))
            
            # model_tea.load_state_dict(new_teacher_dict)

            if batch_idx != 0 and batch_idx % 200 == 0:
                io.cprint('batch: %d, _loss: %f' %(batch_idx, MTLoss))

        io.cprint('train %d, loss: %f' % (epoch, train_loss*1.0/count))
        if cfg.TRAIN.SCHEDULER == 'cos':
            scheduler.step()
        elif cfg.TRAIN.SCHEDULER == 'step':
            if opt.param_groups[0]['lr'] > 1e-5:
                scheduler.step()
            if opt.param_groups[0]['lr'] < 1e-5:
                for param_group in opt.param_groups:
                    param_group['lr'] = 1e-5

        ####################
        # Test(validation)
        ####################
        if epoch % 3 == 0:
            cfs_mtx_list = [metric.IouMetric(list(range(l))) for l in cfg.DATASET.DATA.LABEL_NUMBER]
            model.eval()
            all_correct = torch.Tensor([0, 0, 0, 0, 0])
            all_heads_label = [[] for _ in range(len(HM.classes_num))]
            with torch.no_grad():
                for batch_idx, data_ in enumerate(validation_loader):
                    points_centered, labels, colors, label_weights = data_
                    if labels.shape[0] < cfg.TRAIN.BATCH_SIZE:
                        break
                    points_clrs = torch.FloatTensor(np.concatenate([points_centered, colors], axis=-1))
                    points_clrs = points_clrs.to(device).permute(0, 2, 1)  # (batch_size, dim, nums_point)
                    labels = torch.LongTensor(labels).to(device)
                    label_weights = torch.Tensor(label_weights).to(device)
                    num_points = labels.size()[1]
                    batch_size = labels.size()[0]
                    labels_np = labels.cpu().detach().numpy()
                    labels = torch.chunk(labels, 5, dim=2)
                    opt.zero_grad()
                    if args.model == 'point_transformer':
                        feat = points_clrs
                        coord = points_clrs[:,:3,:]
                        offset = torch.arange(0,cfg.TRAIN.BATCH_SIZE+1)*2048
                        offset = offset.to('cuda')
                        offset = offset.to(torch.int32)
                        seg_pred = model(coord, feat, offset)
                    elif args.model == 'pt_v3':
                        feat = points_clrs
                        coord = points_clrs[:,:3,:]
                        offset = torch.arange(1,cfg.TRAIN.BATCH_SIZE+1)*2048
                        offset = offset.to('cuda')
                        offset = offset.to(torch.int32)

                        feat = min_max_normalize(feat, range_min=-1, range_max=1)
                        coord = min_max_normalize(coord, range_min=-1, range_max=1)
                        feat = feat.to(device)
                        coord = coord.to(device)

                        if len(feat.size())>2: # means x0:(b, c ,n), need to be catted to (b*n, c)
                            feat = feat.transpose(1,2).contiguous() # po(b, n, 3), x0(b, n, c=3)
                            coord = coord.transpose(1,2).contiguous()
                            coord = torch.cat([coord_split.squeeze() for coord_split in coord.split(1,0)])
                            feat = torch.cat([feat_split.squeeze() for feat_split in feat.split(1,0)]) 

                        input = {
                            "feat" : feat,
                            "offset" : offset,
                            "coord" : coord,
                            "grid_size" : 0.01
                        }
                        seg_pred = model(input)
                    else:
                        seg_pred = model(points_clrs)
                    total_num += num_points*batch_size
                    if l == -1:
                        for i in range(len(seg_pred)):
                            seg_pred_i = seg_pred[i].permute(0, 2, 1).contiguous() #(batch_size, num_points, cls)
                            all_correct[i] += cal_correct(seg_pred_i, labels[i])
                            pred_np = np.argmax(seg_pred_i.cpu().detach().numpy(), 2)
                            cfs_mtx_list[i].update(pred_np, labels_np[..., i])
                            all_heads_label[i].append(pred_np.reshape(-1))
                    else:
                        seg_pred = seg_pred.permute(0, 2, 1).contiguous()
                        all_correct[l] += cal_correct(seg_pred, labels[l])
                        pred_np = np.argmax(seg_pred.cpu().detach().numpy(), 2)
                        cfs_mtx_list[l].update(pred_np, labels_np[..., l])
                if l == -1:
                    all_heads_label = np.asarray([np.concatenate(l) for l in all_heads_label]).transpose()
                    scores = metric.HierarchicalConsistency.cal_consistency_rate(HM, all_heads_label)
                    io.cprint('consistency score: {}'.format(scores))
            io.cprint('test aver acc: {}'.format({i: crt*1.0/total_num for i, crt in enumerate(all_correct)}))
            io.cprint('eval avg class IoU: {}'.format('\n'.join([str(m.avg_iou()) for m in cfs_mtx_list])))


        if epoch % 5 == 0:
            save_model(model, cfg, args, 'model')
    save_model(model, cfg, args, 'model_final')


if __name__ == "__main__":
    # Training settings
    parser = argparse.ArgumentParser(description='Point Cloud Part Segmentation')
    parser.add_argument('--exp_name', type=str, default='exp', metavar='N',
                        help='Name of the experiment')
    parser.add_argument('--model', type=str, default='pointnet2', metavar='N',
                        choices=['dgcnn', 'pointnet2', 'pointcnn','point_transformer','pt_v3'],
                        help='Model to use, [dgcnn, pointnet2, pointcnn, point_transformer]')
    parser.add_argument('--eval', type=bool,  default=False,
                        help='evaluate the model')   
    parser.add_argument('--mc_level', type=int, default=-1, help='label level to use; -1 means all')      
    args = parser.parse_args()

    abs_cfg_dir = os.path.abspath(os.path.join(__file__, "../configs"))
    config.merge_cfg_from_dir(abs_cfg_dir)
    cfg = config.CONFIG
    
    HM = read_h_matrix_file_list(cfg.DATASET.DATA.H_MATRIX_LIST_FILE)
    _init_()
    name_dict = {True:"eval", False:""}
    io = IOStream('checkpoints/' + args.exp_name + '/{}run.log'.format(name_dict[args.eval]))

    args.cuda = torch.cuda.is_available()
    torch.manual_seed(cfg.DEVICES.SEED)

    if args.cuda:
        torch.cuda.set_device(cfg.DEVICES.GPU_ID[0])
        io.cprint(
            'Using GPU : ' + str(torch.cuda.current_device()) + ' from ' + str(torch.cuda.device_count()) + ' devices')
        torch.cuda.manual_seed(cfg.DEVICES.SEED)
    else:
        io.cprint('Using CPU')

    if not args.eval:
        train(args, io, cfg, HM)
    else:
        test(args, io, cfg, HM)